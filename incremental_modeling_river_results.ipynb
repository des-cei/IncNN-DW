{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a64a328-0b43-49d3-b517-a0a449b4cb33",
   "metadata": {},
   "source": [
    "# Modelado incremental de FPGAs\n",
    "\n",
    "Te recomiendo que te leas el artículo que te adjunto. En él se describe en detalle el problema que queremos abordar, la solución que proponemos, y los resultados obtenidos. En particular sería interesante que leyeses la sección 6, _Modeling Strategy_, donde se explica qué modelos se emplean y cuáles son las características y variables a predecir.\n",
    "\n",
    "## Escenario\n",
    "\n",
    "El cometido del sistema es ir acelerando tareas provenientes de una _workload_ según estas van llegando. Esto se realiza descargando dichas tareas en la lógica reconfigurable de la FPGA tan pronto llegan, siempre y cuando haya recursos disponibles (las tareas quepan dentro de la lógica disponible en el momento).\n",
    "\n",
    "Puesto que cada tarea utiliza únicamente una porción de la lógica, se da el caso de que multiples tareas diferentes son aceleradas de forma simultánea dentro de la FPGA.\n",
    "Esta coexistencia de tareas en la FPGA deriva en una contención en los recursos disponibles (cpu, ram, acceso al bus, etc), provocando que el tiempo de ejecución y el consumo de potencia de una tarea _X_ se vea influenciado por qué otras tarea(s) _Y_ se estén ejecutando en ese instante.\n",
    "\n",
    "## Propuesta\n",
    "\n",
    "Lo que nosotros buscamos es poder modelar esta interacción entre tareas, para ser capaces de predecir el consumo y tiempo de ejecución, y luego tomar decisiones de planificación de tareas inteligentes.\n",
    "\n",
    "Para llevar a cabo esto, hacemos lo siguiente:\n",
    "\n",
    "1. Mientras que el sistema va ejecutando tareas, proceso que se prolonga de forma indefinida en el tiempo, se van realizando mediciones periódicas de consumo de potencia y tiempo de ejecución (para ello se emplea un componente específico que denominamos _Monitor_).\n",
    "   \n",
    "2. Estas mediciones se procesan segun se van obteniendo, generando así un conjunto de observaciones que poder usar para entrenar los modelos. Esto se hace en tiempo de ejecución en el propio procesador de la placa con un módulo de Python.\n",
    "\n",
    "    Dichas observaciones contienen básicamente el uso de la CPU (hemos observado un impacto importante en el rendimiento del sistema), la configuración particular de la FPGA en dicho instante, y las variables a predecir (puesto que se trata de aprendizaje supervisado). _La `tabla 2`del mencionado paper lista los campos dentro de cada observación._\n",
    "\n",
    "3. Conforme las observaciones se van generando, estas se envían a los modelos para actualizarlos de forma incremental. Esto se hace nuevamente con un módulo de Python, empleando la biblioteca [river](https://riverml.xyz/latest/) que está específicamente diseñada para aprendizaje incremental.\n",
    "\n",
    "    El proceso de entrenamiento es algo más complejo, pues intentamos reducir el tiempo de entrenamiento lo máximo posible mediante un mechanismo que gestiona de forma inteligente cuándo deben ser actualizados los modelos (sección 5, _Model Orchestrator for Incremental Learning_, del paper).\n",
    "\n",
    "4. Este proceso se repite de forma indefinida.\n",
    "\n",
    "_Todo esto está dentro del este [repositorio](https://github.com/juanea7/fpga-modeling). No está en estado de revista en estos momentos, pero en caso de que tengas curiosidad..._\n",
    "\n",
    "## Proceso de entrenamiento\n",
    "\n",
    "El proceso de entrenamiento es algo complejo, pero aquí te muestro una versión simplificada con lo esencial.\n",
    "\n",
    "### Aspectos omitidos\n",
    "\n",
    "- No se tiene en cuenta el mecanismo que gestiona el proceso de entrenamiento, simplemente se entrena el modelo con cada observación una a una.\n",
    "- No se muestra el tratamiento de las trazas para pasar de las mediciones realizadas con el _Monitor_, las observaciones presentes en el dataset estás ya correctamente procesadas.\n",
    "- Se han omitido todos los procesos relacionados con la gestión del entrenamiento en tiempo de ejecución (temas relacionados con comunicación entre las distintas partes de la infraestructura).\n",
    "\n",
    "### Dataset\n",
    "\n",
    "El dataset incluido en esta carpeta es en esencia una `DataFrame` de `Pandas`que contiene cada una de las observaciones generadas durante la ejecución de una workload con el sistema real.\n",
    "\n",
    "### Leer dataset con `Pickel`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "553d3f41-1671-4115-8f46-b9a359eafbec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de observaciones en el dataset: 98525\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>kernel</th>\n",
       "      <th>idle</th>\n",
       "      <th>Main</th>\n",
       "      <th>aes</th>\n",
       "      <th>bulk</th>\n",
       "      <th>crs</th>\n",
       "      <th>kmp</th>\n",
       "      <th>knn</th>\n",
       "      <th>merge</th>\n",
       "      <th>nw</th>\n",
       "      <th>queue</th>\n",
       "      <th>stencil2d</th>\n",
       "      <th>stencil3d</th>\n",
       "      <th>strided</th>\n",
       "      <th>Top power</th>\n",
       "      <th>Bottom power</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66.667</td>\n",
       "      <td>11.667</td>\n",
       "      <td>21.667</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.383</td>\n",
       "      <td>0.176</td>\n",
       "      <td>1.121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45.902</td>\n",
       "      <td>11.475</td>\n",
       "      <td>42.623</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.442</td>\n",
       "      <td>0.174</td>\n",
       "      <td>1.712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45.902</td>\n",
       "      <td>11.475</td>\n",
       "      <td>42.623</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.443</td>\n",
       "      <td>0.174</td>\n",
       "      <td>1.173</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     user  kernel    idle  Main  aes  bulk  crs  kmp  knn  merge  nw  queue  \\\n",
       "0  66.667  11.667  21.667     3    0     0    0    1    0      0   0      0   \n",
       "1  45.902  11.475  42.623     2    0     2    1    0    0      0   0      0   \n",
       "2  45.902  11.475  42.623     1    0     2    1    0    0      0   0      0   \n",
       "\n",
       "   stencil2d  stencil3d  strided  Top power  Bottom power   Time  \n",
       "0          0          0        0      1.383         0.176  1.121  \n",
       "1          0          0        0      1.442         0.174  1.712  \n",
       "2          0          0        0      1.443         0.174  1.173  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset_df = pd.read_pickle(\"dataset.pkl\")\n",
    "\n",
    "print(f\"Número de observaciones en el dataset: {len(dataset_df)}\")\n",
    "# Se puede hacer con print, pero así queda más bonitor\n",
    "display(dataset_df[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24d776c-368b-4b4a-8a8f-074ef701d2fd",
   "metadata": {},
   "source": [
    "Es importante tener en cuenta que actualmente el modelo está diseñado para trabajar con [MachSuite](https://breagen.github.io/MachSuite/) un conjunto de benchamarks basados en tareas de aceleración HW condificados en HLS. Nosotros identificamos cada uno de los kernels disponibles con un ID de la siguiente manera:\n",
    "\n",
    "| AES | BULK | CRS | KMP | KNN | MERGE | NW | QUEUE | STENCIL2D | STENCIL3D | STRIDED |\n",
    "| :--------: | :--------: | :--------: | :--------: | :--------: | :--------: | :--------: | :--------: | :--------: | :--------: | :--------: |\n",
    "| 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 |\n",
    "\n",
    "\n",
    "Se puede ver como cada obsercación consta de:\n",
    "- Tres características que describen el uso de la CPU (`user`, `kernel`, `idle`).\n",
    "- Una característica que indica qué tarea está siendo evaluado en base a su ID (`Main`).\n",
    "- El número de replicas de cada tarea que hay presentes en ese momento en la FPGA (`nombre_de_la_tarea`).\n",
    "- Una etiqueta por cada variable a predecir (en este caso tres, consumo del PS, consumo del PL y tiempo de ejecución).\n",
    "\n",
    "### Formatear dataset\n",
    "\n",
    "Para que sea más cómodo trabajar con él, nosotros dividimos le dataset en `features` y `labels`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6b8aab6-ef80-4af8-b725-182211cb5f2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>kernel</th>\n",
       "      <th>idle</th>\n",
       "      <th>Main</th>\n",
       "      <th>aes</th>\n",
       "      <th>bulk</th>\n",
       "      <th>crs</th>\n",
       "      <th>kmp</th>\n",
       "      <th>knn</th>\n",
       "      <th>merge</th>\n",
       "      <th>nw</th>\n",
       "      <th>queue</th>\n",
       "      <th>stencil2d</th>\n",
       "      <th>stencil3d</th>\n",
       "      <th>strided</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66.667</td>\n",
       "      <td>11.667</td>\n",
       "      <td>21.667</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45.902</td>\n",
       "      <td>11.475</td>\n",
       "      <td>42.623</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45.902</td>\n",
       "      <td>11.475</td>\n",
       "      <td>42.623</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     user  kernel    idle  Main  aes  bulk  crs  kmp  knn  merge  nw  queue  \\\n",
       "0  66.667  11.667  21.667     3    0     0    0    1    0      0   0      0   \n",
       "1  45.902  11.475  42.623     2    0     2    1    0    0      0   0      0   \n",
       "2  45.902  11.475  42.623     1    0     2    1    0    0      0   0      0   \n",
       "\n",
       "   stencil2d  stencil3d  strided  \n",
       "0          0          0        0  \n",
       "1          0          0        0  \n",
       "2          0          0        0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Top power</th>\n",
       "      <th>Bottom power</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.383</td>\n",
       "      <td>0.176</td>\n",
       "      <td>1.121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.442</td>\n",
       "      <td>0.174</td>\n",
       "      <td>1.712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.443</td>\n",
       "      <td>0.174</td>\n",
       "      <td>1.173</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Top power  Bottom power   Time\n",
       "0      1.383         0.176  1.121\n",
       "1      1.442         0.174  1.712\n",
       "2      1.443         0.174  1.173"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Extract features\n",
    "features_df = dataset_df.drop([\"Top power\", \"Bottom power\", \"Time\"], axis=1)\n",
    "\n",
    "# Extract labels\n",
    "labels_df = dataset_df[[\"Top power\", \"Bottom power\", \"Time\"]]\n",
    "\n",
    "display(features_df[:3])\n",
    "display(labels_df[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d1c9fe-7204-4c7a-ad36-d744ce95f2b5",
   "metadata": {},
   "source": [
    "### Inicializar los modelos\n",
    "\n",
    "Como hemos comentado antes, nosotros usamos unos modelos específicamente diseñados para aprendizaje incremental."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "801dbcf9-d46b-484f-beea-d48e44624d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import river\n",
    "from river import metrics, preprocessing, forest\n",
    "\n",
    "# PS power model\n",
    "top_power_model = (\n",
    "                river.preprocessing.StandardScaler() |\n",
    "                river.tree.HoeffdingAdaptiveTreeRegressor(\n",
    "                    max_depth=100,\n",
    "                    grace_period=50,\n",
    "                    model_selector_decay=0.05,\n",
    "                    seed=42\n",
    "                )\n",
    "            )\n",
    "\n",
    "# PL power models\n",
    "bottom_power_model = (\n",
    "                river.preprocessing.StandardScaler() |\n",
    "                river.tree.HoeffdingAdaptiveTreeRegressor(\n",
    "                    max_depth=100,\n",
    "                    grace_period=50,\n",
    "                    model_selector_decay=0.05,\n",
    "                    seed=42\n",
    "                )\n",
    "            )\n",
    "\n",
    "# Execution time model\n",
    "time_model = tmp_model = river.forest.ARFRegressor(seed=42, max_features=None, grace_period=50, n_models = 5, max_depth=100, model_selector_decay=0.05)\n",
    "\n",
    "# Model MAPE metrics\n",
    "top_power_mape = river.utils.Rolling(river.metrics.MAPE(), window_size=1000)\n",
    "bottom_power_mape = river.utils.Rolling(river.metrics.MAPE(), window_size=1000)\n",
    "time_mape = river.utils.Rolling(river.metrics.MAPE(), window_size=1000)\n",
    "\n",
    "# List of metrics and models\n",
    "models = [top_power_model, bottom_power_model, time_model]\n",
    "metrics = [top_power_mape, bottom_power_mape, time_mape]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b12fed-eba1-40a2-b4ee-38fa7d78b7fd",
   "metadata": {},
   "source": [
    "### Entrenar los modelos con el dataset\n",
    "\n",
    "Iteramos sobre el dataset, actualizando los modelos con cada una de las observaciones de forma incremental, el proceso es básicamente este:\n",
    "1. Convertimos las características al tipo de datos que nos conviene con la función `features_labels_accommodation()`. Esta no es la manera óptima. Esa conversión se hará a la hora de generar el dataset, pero ahora mismo tiene que ser así."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77782574-4ef9-4eac-89f5-001162d5eddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_labels_accommodation(features, labels):\n",
    "        \"\"\"Perform accomodation on features and labels. Type casting...\"\"\"\n",
    "\n",
    "        features[\"user\"] = float(features[\"user\"])\n",
    "        features[\"kernel\"] = float(features[\"kernel\"])\n",
    "        features[\"idle\"] = float(features[\"idle\"])\n",
    "\n",
    "        features[\"Main\"] = int(features[\"Main\"])\n",
    "        features[\"aes\"] = int(features[\"aes\"])\n",
    "        features[\"bulk\"] = int(features[\"bulk\"])\n",
    "        features[\"crs\"] = int(features[\"crs\"])\n",
    "        features[\"kmp\"] = int(features[\"kmp\"])\n",
    "        features[\"knn\"] = int(features[\"knn\"])\n",
    "        features[\"merge\"] = int(features[\"merge\"])\n",
    "        features[\"nw\"] = int(features[\"nw\"])\n",
    "        features[\"queue\"] = int(features[\"queue\"])\n",
    "        features[\"stencil2d\"] = int(features[\"stencil2d\"])\n",
    "        features[\"stencil3d\"] = int(features[\"stencil3d\"])\n",
    "        features[\"strided\"] = int(features[\"strided\"])\n",
    "\n",
    "        # Get each model label\n",
    "        labels = [float(labels[key]) for key in labels]\n",
    "\n",
    "        return features, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d4261d-17b7-40c3-a896-96da18c24798",
   "metadata": {},
   "source": [
    "2. Hacemos una predicción con el modelo para la observación actual.\n",
    "\n",
    "3. Entrenamos el modelo con la observación actual.\n",
    "\n",
    "4. Actualizamos la metrica de error usando la predicción del modelos y el valor real medido.\n",
    "\n",
    "Acontinuación se muestra el proceso de entrenamiento. _Se ha hecho solo para las primeras 5,000 observaciones para ahorrar tiempo._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f1c037-4465-40c1-b439-1bef4c13bb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "def rolling(data):\n",
    "    # Extract the MAPE values from the nested list\n",
    "    error_data = [point[1] for point in data]\n",
    "    rolling_mean = np.zeros(len(error_data)-1999)\n",
    "    rolling_sdv = np.zeros(len(error_data)-1999)\n",
    "\n",
    "    # Compute the rolling mean for 1000 values\n",
    "    buffer = error_data[1000:2000]\n",
    "    rolling_mean[0] = np.mean(buffer)\n",
    "    rolling_sdv[0] = np.std(buffer)\n",
    "    j = 0\n",
    "    for i in range(2000, len(error_data)):\n",
    "        buffer[j] = error_data[i]\n",
    "        rolling_mean[i-1999] = np.mean(buffer)\n",
    "        rolling_sdv[i-1999] = np.std(buffer)\n",
    "        j += 1\n",
    "        if j == 1000:\n",
    "            j = 0\n",
    "    return rolling_mean, rolling_sdv\n",
    "    \n",
    "\n",
    "# Loop over the observations\n",
    "infer_time_TP = 0\n",
    "train_time_TP = 0\n",
    "infer_time_BP = 0\n",
    "train_time_BP = 0\n",
    "infer_time_Time = 0\n",
    "train_time_Time = 0\n",
    "\n",
    "MAPE_mean_TP = []\n",
    "MAPE_std_TP = []\n",
    "MAPE_mean_BP = []\n",
    "MAPE_std_BP = []\n",
    "MAPE_mean_Time = []\n",
    "MAPE_std_Time = []\n",
    "\n",
    "for i in range(5):\n",
    "    buffer_MAPE_TP = []\n",
    "    buffer_MAPE_BP = []\n",
    "    buffer_MAPE_Time = []\n",
    "    j = 0\n",
    "    for features, labels in river.stream.iter_pandas(features_df, labels_df, shuffle=False, seed=42):\n",
    "        # Features and labels accommodation\n",
    "        features, labels = features_labels_accommodation(features, labels)\n",
    "        \n",
    "        start_time = time.perf_counter()\n",
    "        # Make a prediction\n",
    "        y_pred = top_power_model.predict_one(features)\n",
    "        end_time = time.perf_counter()\n",
    "        infer_time_TP = infer_time_TP + end_time - start_time\n",
    "        start_time = time.perf_counter()\n",
    "        # Train the model\n",
    "        top_power_model.learn_one(features, labels[0])\n",
    "        # Update metric\n",
    "        top_power_mape.update(labels[0], y_pred)\n",
    "        end_time = time.perf_counter()\n",
    "        train_time_TP = train_time_TP + end_time - start_time\n",
    "        error = (labels[0]-y_pred)/labels[0]*100\n",
    "        loss = [j, error]\n",
    "        buffer_MAPE_TP.append(loss)\n",
    "        \n",
    "\n",
    "        start_time = time.perf_counter()\n",
    "        # Make a prediction\n",
    "        y_pred = bottom_power_model.predict_one(features)\n",
    "        end_time = time.perf_counter()\n",
    "        infer_time_BP = infer_time_BP + end_time - start_time\n",
    "        start_time = time.perf_counter()\n",
    "        # Train the model\n",
    "        bottom_power_model.learn_one(features, labels[1])\n",
    "        # Update metric\n",
    "        bottom_power_mape.update(labels[1], y_pred)\n",
    "        end_time = time.perf_counter()\n",
    "        train_time_BP = train_time_BP + end_time - start_time\n",
    "        error = (labels[1]-y_pred)/labels[1]*100\n",
    "        loss = [j, error]\n",
    "        buffer_MAPE_BP.append(loss)\n",
    "        \n",
    "\n",
    "        start_time = time.perf_counter()\n",
    "        # Make a prediction\n",
    "        y_pred = time_model.predict_one(features)\n",
    "        end_time = time.perf_counter()\n",
    "        infer_time_Time = infer_time_Time + end_time - start_time\n",
    "        start_time = time.perf_counter()\n",
    "        # Train the model\n",
    "        time_model.learn_one(features, labels[2])\n",
    "        # Update metric\n",
    "        time_mape.update(labels[2], y_pred)\n",
    "        end_time = time.perf_counter()\n",
    "        train_time_Time = train_time_Time + end_time - start_time\n",
    "        error = (labels[2]-y_pred)/labels[2]*100\n",
    "        loss = [j, error]\n",
    "        buffer_MAPE_Time.append(loss)\n",
    "        j += 1\n",
    "    \n",
    "    rolling_mean, rollind_std = rolling(buffer_MAPE_TP)\n",
    "    dummy_mean = np.mean(rolling_mean)\n",
    "    MAPE_mean_TP.append(dummy_mean)\n",
    "    dummy_std = np.mean(rollind_std)\n",
    "    MAPE_std_TP.append(dummy_std)\n",
    "    del rolling_mean, rollind_std, buffer_MAPE_TP\n",
    "\n",
    "    rolling_mean, rollind_std = rolling(buffer_MAPE_BP)\n",
    "    dummy_mean = np.mean(rolling_mean)\n",
    "    MAPE_mean_BP.append(dummy_mean)\n",
    "    dummy_std = np.mean(rollind_std)\n",
    "    MAPE_std_BP.append(dummy_std)\n",
    "    del rolling_mean, rollind_std, buffer_MAPE_BP\n",
    "    \n",
    "    rolling_mean, rollind_std = rolling(buffer_MAPE_Time)\n",
    "    dummy_mean = np.mean(rolling_mean)\n",
    "    MAPE_mean_Time.append(dummy_mean)\n",
    "    dummy_std = np.mean(rollind_std)\n",
    "    MAPE_std_Time.append(dummy_std)\n",
    "    del rolling_mean, rollind_std, buffer_MAPE_Time\n",
    "\n",
    "\"\"\"\n",
    "infer_time_TP = infer_time_TP / (98525 * 5)\n",
    "print('Top power Model. Infer time: ' + str(infer_time_TP) + ' Train time: ' + str(train_time_TP))\n",
    "infer_time_BP = infer_time_BP / (98525 * 5)\n",
    "print('Bottom power Model. Infer time: ' + str(infer_time_BP) + ' Train time: ' + str(train_time_BP))\n",
    "infer_time_Time = infer_time_Time / (98525 * 5)\n",
    "print('Time Model. Infer time: ' + str(infer_time_Time) + ' Train time: ' + str(train_time_Time))\n",
    "\"\"\"\n",
    "\n",
    "model_type = [\"Top-power\", \"Bottom-power\", \"Time\"]\n",
    "resultados = {\"Top-power\": {}, \"Bottom-power\": {}, \"Time\": {}}\n",
    "for mt in model_type:\n",
    "    resultados[mt] = {\"Mape_mean\": {}, \"Mape_sdv\": {}, \"Mape_mean_dev\": {}, \"Infer_time\": {}, \"Train_time\": {}}\n",
    "\n",
    "resultados[\"Top-power\"]['Mape_mean'] = float(np.mean(MAPE_mean_TP))\n",
    "resultados[\"Top-power\"]['Mape_sdv'] = float(np.mean(MAPE_std_TP))\n",
    "resultados[\"Top-power\"]['Mape_mean_dev'] = float(np.std(MAPE_mean_TP))\n",
    "resultados[\"Top-power\"]['Infer_time'] = infer_time_TP / (98525 * 5)\n",
    "resultados[\"Top-power\"]['Train_time'] = train_time_TP/5\n",
    "\n",
    "resultados[\"Bottom-power\"]['Mape_mean'] = float(np.mean(MAPE_mean_BP))\n",
    "resultados[\"Bottom-power\"]['Mape_sdv'] = float(np.mean(MAPE_std_BP))\n",
    "resultados[\"Bottom-power\"]['Mape_mean_dev'] = float(np.std(MAPE_mean_BP))\n",
    "resultados[\"Bottom-power\"]['Infer_time'] = infer_time_BP / (98525 * 5)\n",
    "resultados[\"Bottom-power\"]['Train_time'] = train_time_BP/5\n",
    "\n",
    "resultados[\"Time\"]['Mape_mean'] = float(np.mean(MAPE_mean_Time))\n",
    "resultados[\"Time\"]['Mape_sdv'] = float(np.mean(MAPE_std_Time))\n",
    "resultados[\"Time\"]['Mape_mean_dev'] = float(np.std(MAPE_mean_Time))\n",
    "resultados[\"Time\"]['Infer_time'] = infer_time_Time / (98525 * 5)\n",
    "resultados[\"Time\"]['Train_time'] = train_time_Time/5\n",
    "\n",
    "with open(\"river_results.pkl\", \"wb\") as NN_2layers_dict:\n",
    "    pickle.dump(resultados, NN_2layers_dict)\n",
    "NN_2layers_dict.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b286b6b5-791f-444c-9564-4a3eff6f8370",
   "metadata": {},
   "source": [
    "El error en la predicción se puede ver de está forma para cada modelo. Ten en cuenta que la metrica empleada es una media de las últimas 1000 predicciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2371a325-c201-4a83-87b5-48231752fdcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PS Power - MAPE: 3.01%\n",
      "PL Power - MAPE: 2.21%\n",
      "Execution Time - MAPE: 18.62%\n"
     ]
    }
   ],
   "source": [
    "model_names = [\"PS Power\", \"PL Power\", \"Execution Time\"]\n",
    "\n",
    "for model_name, metric in zip(model_names, metrics):\n",
    "    print(f\"{model_name} - MAPE: {round(metric.get(),2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7eb70f-503b-4e7e-b563-5beb6d4a22f2",
   "metadata": {},
   "source": [
    "### Proceso Completo\n",
    "\n",
    "Aquí se repiten todos los pasos anteriores seguidos. Puede tardar un rato puesto que en este caso se van a entrenar todos los modelos con el dataset completo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4fbaf6-96f1-4c7c-b605-6b49ac999fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PS Power - MAPE: 2.6%\n",
      "PL Power - MAPE: 2.2%\n",
      "Execution Time - MAPE: 35.55%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import river\n",
    "import sys\n",
    "from river import metrics, preprocessing, forest\n",
    "\n",
    "def features_labels_accommodation(features, labels):\n",
    "        \"\"\"Perform accomodation on features and labels. Type casting...\"\"\"\n",
    "\n",
    "        features[\"user\"] = float(features[\"user\"])\n",
    "        features[\"kernel\"] = float(features[\"kernel\"])\n",
    "        features[\"idle\"] = float(features[\"idle\"])\n",
    "\n",
    "        features[\"Main\"] = int(features[\"Main\"])\n",
    "        features[\"aes\"] = int(features[\"aes\"])\n",
    "        features[\"bulk\"] = int(features[\"bulk\"])\n",
    "        features[\"crs\"] = int(features[\"crs\"])\n",
    "        features[\"kmp\"] = int(features[\"kmp\"])\n",
    "        features[\"knn\"] = int(features[\"knn\"])\n",
    "        features[\"merge\"] = int(features[\"merge\"])\n",
    "        features[\"nw\"] = int(features[\"nw\"])\n",
    "        features[\"queue\"] = int(features[\"queue\"])\n",
    "        features[\"stencil2d\"] = int(features[\"stencil2d\"])\n",
    "        features[\"stencil3d\"] = int(features[\"stencil3d\"])\n",
    "        features[\"strided\"] = int(features[\"strided\"])\n",
    "\n",
    "        # Get each model label\n",
    "        labels = [float(labels[key]) for key in labels]\n",
    "\n",
    "        return features, labels\n",
    "\n",
    "\n",
    "#\n",
    "# Dataset\n",
    "#\n",
    "\n",
    "# Read dataset\n",
    "dataset_df = pd.read_pickle(\"dataset.pkl\")\n",
    "\n",
    "# Extract features\n",
    "features_df = dataset_df.drop([\"Top power\", \"Bottom power\", \"Time\"], axis=1)\n",
    "\n",
    "# Extract labels\n",
    "labels_df = dataset_df[[\"Top power\", \"Bottom power\", \"Time\"]]\n",
    "\n",
    "\n",
    "#\n",
    "# Model Initialization\n",
    "#\n",
    "\n",
    "# Initialize PS power model\n",
    "top_power_model = (\n",
    "                river.preprocessing.StandardScaler() |\n",
    "                river.tree.HoeffdingAdaptiveTreeRegressor(\n",
    "                    max_depth=100,\n",
    "                    grace_period=50,\n",
    "                    model_selector_decay=0.05,\n",
    "                    seed=42\n",
    "                )\n",
    "            )\n",
    "\n",
    "# Initialize PL power models\n",
    "bottom_power_model = (\n",
    "                river.preprocessing.StandardScaler() |\n",
    "                river.tree.HoeffdingAdaptiveTreeRegressor(\n",
    "                    max_depth=100,\n",
    "                    grace_period=50,\n",
    "                    model_selector_decay=0.05,\n",
    "                    seed=42\n",
    "                )\n",
    "            )\n",
    "\n",
    "# Initialize Execution time model\n",
    "time_model = tmp_model = river.forest.ARFRegressor(seed=42, max_features=None, grace_period=50, n_models = 5, max_depth=100, model_selector_decay=0.05)\n",
    "\n",
    "# Create model MAPE metrics\n",
    "top_power_mape = river.utils.Rolling(river.metrics.MAPE(), window_size=1000)\n",
    "bottom_power_mape = river.utils.Rolling(river.metrics.MAPE(), window_size=1000)\n",
    "time_mape = river.utils.Rolling(river.metrics.MAPE(), window_size=1000)\n",
    "\n",
    "# List of metrics and models\n",
    "models = [top_power_model, bottom_power_model, time_model]\n",
    "metrics = [top_power_mape, bottom_power_mape, time_mape]\n",
    "\n",
    "\n",
    "#\n",
    "# Model Train\n",
    "#\n",
    "\n",
    "# Loop over the observations\n",
    "for features, labels in river.stream.iter_pandas(features_df, labels_df, shuffle=False, seed=42):\n",
    "\n",
    "    # Features and labels accommodation\n",
    "    features, labels = features_labels_accommodation(features, labels)\n",
    "\n",
    "    for model, metric, label in zip(models, metrics, labels):\n",
    "        # Make a prediction\n",
    "        y_pred = model.predict_one(features)\n",
    "        # Train the model\n",
    "        model.learn_one(features, label)\n",
    "        # Update metric\n",
    "        metric.update(label, y_pred)\n",
    "\n",
    "# Print metrics\n",
    "for model_name, metric in zip(model_names, metrics):\n",
    "    print(f\"{model_name} - MAPE: {round(metric.get(),2)}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TFM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
