{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a7eb70f-503b-4e7e-b563-5beb6d4a22f2",
   "metadata": {},
   "source": [
    "### Proceso river\n",
    "\n",
    "Puede tardar un rato puesto que en este caso se van a entrenar todos los modelos con el dataset completo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c4fbaf6-96f1-4c7c-b605-6b49ac999fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Usuario\\anaconda3\\envs\\cnntabular\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.7.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PS Power - MAPE: 3.01%\n",
      "PL Power - MAPE: 2.67%\n",
      "Execution Time - MAPE: 41.57%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import river\n",
    "import sys\n",
    "from river import metrics, preprocessing, forest\n",
    "    \n",
    "def features_labels_accommodation(features, labels):\n",
    "        \"\"\"Perform accomodation on features and labels. Type casting...\"\"\"\n",
    "        \n",
    "        features[\"user\"] = float(features[\"user\"])\n",
    "        features[\"kernel\"] = float(features[\"kernel\"])\n",
    "        features[\"idle\"] = float(features[\"idle\"])\n",
    "\n",
    "        features[\"Main\"] = int(features[\"Main\"])\n",
    "        features[\"aes\"] = int(features[\"aes\"])\n",
    "        features[\"bulk\"] = int(features[\"bulk\"])\n",
    "        features[\"crs\"] = int(features[\"crs\"])\n",
    "        features[\"kmp\"] = int(features[\"kmp\"])\n",
    "        features[\"knn\"] = int(features[\"knn\"])\n",
    "        features[\"merge\"] = int(features[\"merge\"])\n",
    "        features[\"nw\"] = int(features[\"nw\"])\n",
    "        features[\"queue\"] = int(features[\"queue\"])\n",
    "        features[\"stencil2d\"] = int(features[\"stencil2d\"])\n",
    "        features[\"stencil3d\"] = int(features[\"stencil3d\"])\n",
    "        features[\"strided\"] = int(features[\"strided\"])\n",
    "\n",
    "        # Get each model label\n",
    "        labels = [float(labels[key]) for key in labels]\n",
    "\n",
    "        return features, labels\n",
    "\n",
    "\n",
    "#\n",
    "# Dataset\n",
    "#\n",
    "\n",
    "# Read dataset\n",
    "dataset_df = pd.read_pickle(\"dataset.pkl\")\n",
    "\n",
    "# Extract features\n",
    "features_df = dataset_df.drop([\"Top power\", \"Bottom power\", \"Time\"], axis=1)\n",
    "\n",
    "# Extract labels\n",
    "labels_df = dataset_df[[\"Top power\", \"Bottom power\", \"Time\"]]\n",
    "TP = labels_df.iloc[:, 0] #size 98525\n",
    "BP = labels_df.iloc[:, 1]\n",
    "Time = labels_df.iloc[:, 2]\n",
    "\n",
    "#\n",
    "# Model Initialization\n",
    "#\n",
    "\n",
    "# Initialize PS power model\n",
    "top_power_model = (\n",
    "                river.preprocessing.StandardScaler() |\n",
    "                river.tree.HoeffdingAdaptiveTreeRegressor(\n",
    "                    max_depth=100,\n",
    "                    grace_period=50,\n",
    "                    model_selector_decay=0.05,\n",
    "                    seed=42\n",
    "                )\n",
    "            )\n",
    "\n",
    "# Initialize PL power models\n",
    "bottom_power_model = (\n",
    "                river.preprocessing.StandardScaler() |\n",
    "                river.tree.HoeffdingAdaptiveTreeRegressor(\n",
    "                    max_depth=100,\n",
    "                    grace_period=50,\n",
    "                    model_selector_decay=0.05,\n",
    "                    seed=42\n",
    "                )\n",
    "            )\n",
    "\n",
    "# Initialize Execution time model\n",
    "time_model = tmp_model = river.forest.ARFRegressor(seed=42, max_features=None, grace_period=50, n_models = 5, max_depth=100, model_selector_decay=0.05)\n",
    "\n",
    "# Create model MAPE metrics\n",
    "top_power_mape = river.utils.Rolling(river.metrics.MAPE(), window_size=1000)\n",
    "bottom_power_mape = river.utils.Rolling(river.metrics.MAPE(), window_size=1000)\n",
    "time_mape = river.utils.Rolling(river.metrics.MAPE(), window_size=1000)\n",
    "\n",
    "# List of metrics and models\n",
    "models = [top_power_model, bottom_power_model, time_model]\n",
    "metrics = [top_power_mape, bottom_power_mape, time_mape]\n",
    "model_names = [\"PS Power\", \"PL Power\", \"Execution Time\"]\n",
    "\n",
    "#\n",
    "# Model Train\n",
    "#\n",
    "\n",
    "top_model_metric_history = []\n",
    "bottom_model_metric_history = []\n",
    "time_model_metric_history = []\n",
    "\n",
    "# Loop over the observations\n",
    "for features, labels in river.stream.iter_pandas(features_df, labels_df, shuffle=False, seed=42):\n",
    "\n",
    "    # Features and labels accommodation\n",
    "    features, labels = features_labels_accommodation(features, labels)\n",
    "    for model_type, (model, metric, label) in enumerate(zip(models, metrics, labels)):\n",
    "        # Make a prediction\n",
    "        y_pred = model.predict_one(features)\n",
    "        # Train the model\n",
    "        model.learn_one(features, label)\n",
    "        # Update metric\n",
    "        metric.update(label, y_pred)\n",
    "        \n",
    "        \n",
    "\n",
    "        if model_type == 0:\n",
    "            top_model_metric_history.append(metric.get())\n",
    "        elif model_type == 1:\n",
    "            bottom_model_metric_history.append(metric.get())\n",
    "        else:\n",
    "            time_model_metric_history.append(metric.get())\n",
    "\n",
    "# Print metrics\n",
    "for model_name, metric in zip(model_names, metrics):\n",
    "    print(f\"{model_name} - MAPE: {round(metric.get(),2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae86f7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "##### ADAPTIVE CONTINUOUS LEARNING APPROACH OF TWO LAYER NEURAL NETWORKS #####\n",
    "##############################################################################\n",
    "\n",
    "###########################################################\n",
    "##### DEFINICIÓN DE LIBRERÍAS Y LECTURA BASE DE DATOS #####\n",
    "###########################################################\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "dataset = pd.read_pickle(\"dataset.pkl\")\n",
    "\n",
    "# Path to store obtained results\n",
    "STORE_PATH = \"C:/Users/Usuario/Desktop/Universidad/UPM/TFM/Pruebas iniciales\"\n",
    "\n",
    "os.chdir(STORE_PATH)\n",
    "\n",
    "# Extract features\n",
    "features = dataset.drop([\"Top power\", \"Bottom power\", \"Time\"], axis=1)\n",
    "\n",
    "# Extract labels\n",
    "labels = dataset[[\"Top power\", \"Bottom power\", \"Time\"]]\n",
    "TP = labels.iloc[:, 0] #size 98525\n",
    "BP = labels.iloc[:, 1]\n",
    "Time = labels.iloc[:, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d98b134a",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "##### DEFINICIÓN DE REDES #####\n",
    "###############################\n",
    "\n",
    "# Listas con los parámetros de los tres mejores modelos de dos capas con dropout de cada tipo de modelo\n",
    "Model_TP_1 = [16, 0, 8]\n",
    "Model_TP_2 = [32, 0, 4]\n",
    "Model_TP_3 = [12, 0, 12]\n",
    "\n",
    "Model_BP_1 = [32, 0.1, 20]\n",
    "Model_BP_2 = [32, 0.1, 12]\n",
    "Model_BP_3 = [28, 0.2, 24]\n",
    "\n",
    "Model_Time_1 = [32, 0, 20]\n",
    "Model_Time_2 = [32, 0.1, 24]\n",
    "Model_Time_3 = [28, 0.1, 16]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58791b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Top Power models\n",
      "\n",
      "Continuous training of a two layer neural network: First layer = 16 neurones, Dropout = 0, Second layer = 8 neurones\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nwith pd.ExcelWriter(\"Resultados_entrenamiento_continuo_idle_TP.xlsx\") as writer: \\n    df_resultados_error_cont_Model_TP_1 = pd.DataFrame(resultados_error_cont_Model_TP_1)\\n    df_resultados_error_cont_Model_TP_1.to_excel(writer, sheet_name=\"Model 1\")\\n    #df_resultados_error_cont_Model_TP_2 = pd.DataFrame(resultados_error_cont_Model_TP_2)\\n    #df_resultados_error_cont_Model_TP_2.to_excel(writer, sheet_name=\"Model 2\")\\n    #df_resultados_error_cont_Model_TP_3 = pd.DataFrame(resultados_error_cont_Model_TP_3)\\n    #df_resultados_error_cont_Model_TP_3.to_excel(writer, sheet_name=\"Model 3\")\\n\\n\\n\\n\\nprint(\"Training Bottom Power models\")\\nresultados_error_cont_Model_BP_1 = train_cont_model_2layer(features, BP, Model_BP_1)\\n#resultados_error_cont_Model_BP_2 = train_cont_model_2layer(features, BP, Model_BP_2)\\n#resultados_error_cont_Model_BP_3 = train_cont_model_2layer(features, BP, Model_BP_3)\\n\\nwith pd.ExcelWriter(\"Resultados_entrenamiento_continuo_idle_BP.xlsx\") as writer: \\n    df_resultados_error_cont_Model_BP_1 = pd.DataFrame(resultados_error_cont_Model_BP_1)\\n    df_resultados_error_cont_Model_BP_1.to_excel(writer, sheet_name=\"Model 1\")\\n    #df_resultados_error_cont_Model_BP_2 = pd.DataFrame(resultados_error_cont_Model_BP_2)\\n    #df_resultados_error_cont_Model_BP_2.to_excel(writer, sheet_name=\"Model 2\")\\n    #df_resultados_error_cont_Model_BP_3 = pd.DataFrame(resultados_error_cont_Model_BP_3)\\n    #df_resultados_error_cont_Model_BP_3.to_excel(writer, sheet_name=\"Model 3\")\\n\\nprint(\"Training Time models\")\\nresultados_error_cont_Model_Time_1 = train_cont_model_2layer(features, Time, Model_Time_1)\\n#resultados_error_cont_Model_Time_2 = train_cont_model_2layer(features, Time, Model_Time_2)\\n#resultados_error_cont_Model_Time_3 = train_cont_model_2layer(features, Time, Model_Time_3)\\n\\nwith pd.ExcelWriter(\"Resultados_entrenamiento_continuo_idle_Time.xlsx\") as writer: \\n    df_resultados_error_cont_Model_Time_1 = pd.DataFrame(resultados_error_cont_Model_Time_1)\\n    df_resultados_error_cont_Model_Time_1.to_excel(writer, sheet_name=\"Model 1\")\\n    #df_resultados_error_cont_Model_Time_2 = pd.DataFrame(resultados_error_cont_Model_Time_2)\\n    #df_resultados_error_cont_Model_Time_2.to_excel(writer, sheet_name=\"Model 2\")\\n    #df_resultados_error_cont_Model_Time_3 = pd.DataFrame(resultados_error_cont_Model_Time_3)\\n    #df_resultados_error_cont_Model_Time_3.to_excel(writer, sheet_name=\"Model 3\")\\n\\n\\nprueba_tiempos_TP = train_infer_times(features, TP, Model_TP_1)\\nprueba_tiempos_BP = train_infer_times(features, BP, Model_BP_1)\\nprueba_tiempos_Time = train_infer_times(features, Time, Model_Time_1)\\nwith pd.ExcelWriter(\"Prueba_tiempos_train_infer.xlsx\") as writer: \\n    df_prueba_tiempos_TP = pd.DataFrame(prueba_tiempos_TP)\\n    df_prueba_tiempos_TP.to_excel(writer, sheet_name=\"Model TP\")\\n    df_prueba_tiempos_BP = pd.DataFrame(prueba_tiempos_BP)\\n    df_prueba_tiempos_BP.to_excel(writer, sheet_name=\"Model BP\")\\n    df_prueba_tiempos_Time = pd.DataFrame(prueba_tiempos_Time)\\n    df_prueba_tiempos_Time.to_excel(writer, sheet_name=\"Model Time\")\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "######################################\n",
    "##### ENTRENAMIENTO DE LAS REDES #####\n",
    "######################################\n",
    "\n",
    "from incremental_modeling_functions import train_cont_model_2layer, train_infer_times\n",
    "\n",
    "# Lista para guardar los resultados\n",
    "print(\"Training Top Power models\")\n",
    "resultados_error_cont_Model_TP_1 = train_cont_model_2layer(features, TP, Model_TP_1)\n",
    "resultados_error_cont_Model_TP_2 = train_cont_model_2layer(features, TP, Model_TP_2)\n",
    "#resultados_error_cont_Model_TP_3 = train_cont_model_2layer(features, TP, Model_TP_3)\n",
    "\n",
    "with pd.ExcelWriter(\"Resultados_entrenamiento_continuo_idle_TP.xlsx\") as writer: \n",
    "    df_resultados_error_cont_Model_TP_1 = pd.DataFrame(resultados_error_cont_Model_TP_1)\n",
    "    df_resultados_error_cont_Model_TP_1.to_excel(writer, sheet_name=\"Model 1\")\n",
    "    df_resultados_error_cont_Model_TP_2 = pd.DataFrame(resultados_error_cont_Model_TP_2)\n",
    "    df_resultados_error_cont_Model_TP_2.to_excel(writer, sheet_name=\"Model 2\")\n",
    "    #df_resultados_error_cont_Model_TP_3 = pd.DataFrame(resultados_error_cont_Model_TP_3)\n",
    "    #df_resultados_error_cont_Model_TP_3.to_excel(writer, sheet_name=\"Model 3\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Training Bottom Power models\")\n",
    "resultados_error_cont_Model_BP_1 = train_cont_model_2layer(features, BP, Model_BP_1)\n",
    "resultados_error_cont_Model_BP_2 = train_cont_model_2layer(features, BP, Model_BP_2)\n",
    "#resultados_error_cont_Model_BP_3 = train_cont_model_2layer(features, BP, Model_BP_3)\n",
    "\n",
    "with pd.ExcelWriter(\"Resultados_entrenamiento_continuo_idle_BP.xlsx\") as writer: \n",
    "    df_resultados_error_cont_Model_BP_1 = pd.DataFrame(resultados_error_cont_Model_BP_1)\n",
    "    df_resultados_error_cont_Model_BP_1.to_excel(writer, sheet_name=\"Model 1\")\n",
    "    df_resultados_error_cont_Model_BP_2 = pd.DataFrame(resultados_error_cont_Model_BP_2)\n",
    "    df_resultados_error_cont_Model_BP_2.to_excel(writer, sheet_name=\"Model 2\")\n",
    "    #df_resultados_error_cont_Model_BP_3 = pd.DataFrame(resultados_error_cont_Model_BP_3)\n",
    "    #df_resultados_error_cont_Model_BP_3.to_excel(writer, sheet_name=\"Model 3\")\n",
    "\n",
    "print(\"Training Time models\")\n",
    "resultados_error_cont_Model_Time_1 = train_cont_model_2layer(features, Time, Model_Time_1)\n",
    "resultados_error_cont_Model_Time_2 = train_cont_model_2layer(features, Time, Model_Time_2)\n",
    "#resultados_error_cont_Model_Time_3 = train_cont_model_2layer(features, Time, Model_Time_3)\n",
    "\n",
    "with pd.ExcelWriter(\"Resultados_entrenamiento_continuo_idle_Time.xlsx\") as writer: \n",
    "    df_resultados_error_cont_Model_Time_1 = pd.DataFrame(resultados_error_cont_Model_Time_1)\n",
    "    df_resultados_error_cont_Model_Time_1.to_excel(writer, sheet_name=\"Model 1\")\n",
    "    df_resultados_error_cont_Model_Time_2 = pd.DataFrame(resultados_error_cont_Model_Time_2)\n",
    "    df_resultados_error_cont_Model_Time_2.to_excel(writer, sheet_name=\"Model 2\")\n",
    "    #df_resultados_error_cont_Model_Time_3 = pd.DataFrame(resultados_error_cont_Model_Time_3)\n",
    "    #df_resultados_error_cont_Model_Time_3.to_excel(writer, sheet_name=\"Model 3\")\n",
    "\n",
    "\n",
    "prueba_tiempos_TP = train_infer_times(features, TP, Model_TP_1)\n",
    "prueba_tiempos_BP = train_infer_times(features, BP, Model_BP_1)\n",
    "prueba_tiempos_Time = train_infer_times(features, Time, Model_Time_1)\n",
    "with pd.ExcelWriter(\"Prueba_tiempos_train_infer.xlsx\") as writer: \n",
    "    df_prueba_tiempos_TP = pd.DataFrame(prueba_tiempos_TP)\n",
    "    df_prueba_tiempos_TP.to_excel(writer, sheet_name=\"Model TP\")\n",
    "    df_prueba_tiempos_BP = pd.DataFrame(prueba_tiempos_BP)\n",
    "    df_prueba_tiempos_BP.to_excel(writer, sheet_name=\"Model BP\")\n",
    "    df_prueba_tiempos_Time = pd.DataFrame(prueba_tiempos_Time)\n",
    "    df_prueba_tiempos_Time.to_excel(writer, sheet_name=\"Model Time\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c3491c1",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# TODO: Not used on-chip. Handle this properly\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mincremental_modeling_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m rolling_mean, plot_best_models\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Preparamos las medias móviles para plotear\u001b[39;00m\n\u001b[0;32m      5\u001b[0m y_values_Model_TP_1 \u001b[38;5;241m=\u001b[39m rolling_mean(resultados_error_cont_Model_TP_1)\n",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# TODO: Not used on-chip. Handle this properly\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mincremental_modeling_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m rolling_mean, plot_best_models\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Preparamos las medias móviles para plotear\u001b[39;00m\n\u001b[0;32m      5\u001b[0m y_values_Model_TP_1 \u001b[38;5;241m=\u001b[39m rolling_mean(resultados_error_cont_Model_TP_1)\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1457\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:701\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1152\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1135\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:312\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2067\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[0;32m   2064\u001b[0m             from_this_thread\u001b[38;5;241m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[0;32m   2066\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads_suspended_single_notification\u001b[38;5;241m.\u001b[39mnotify_thread_suspended(thread_id, stop_reason):\n\u001b[1;32m-> 2067\u001b[0m         keep_suspended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuspend_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_this_thread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes_tracker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2069\u001b[0m frames_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2071\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keep_suspended:\n\u001b[0;32m   2072\u001b[0m     \u001b[38;5;66;03m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2103\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[0;32m   2100\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_input_hook()\n\u001b[0;32m   2102\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_internal_commands()\n\u001b[1;32m-> 2103\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2105\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mid\u001b[39m(frame)))\n\u001b[0;32m   2107\u001b[0m \u001b[38;5;66;03m# process any stepping instructions\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    " # TODO: Not used on-chip. Handle this properly\n",
    "from incremental_modeling_functions import rolling_mean, plot_best_models\n",
    "\n",
    "# Preparamos las medias móviles para plotear\n",
    "y_values_Model_TP_1 = rolling_mean(resultados_error_cont_Model_TP_1)\n",
    "#y_values_Model_TP_2 = rolling_mean(resultados_error_cont_Model_TP_2)\n",
    "#y_values_Model_TP_3 = rolling_mean(resultados_error_cont_Model_TP_3)\n",
    "\n",
    "y_values_Model_BP_1 = rolling_mean(resultados_error_cont_Model_BP_1)\n",
    "#y_values_Model_BP_2 = rolling_mean(resultados_error_cont_Model_BP_2)\n",
    "#y_values_Model_BP_3 = rolling_mean(resultados_error_cont_Model_BP_3)\n",
    "\n",
    "y_values_Model_Time_1 = rolling_mean(resultados_error_cont_Model_Time_1)\n",
    "#y_values_Model_Time_2 = rolling_mean(resultados_error_cont_Model_Time_2)\n",
    "#y_values_Model_Time_3 = rolling_mean(resultados_error_cont_Model_Time_3)\n",
    "\n",
    "# Ploting up to 4 models, river and three best --> only Model_1 is absolutely necessary to plot\n",
    "plot_best_models(\"TP\", Model_1 = y_values_Model_TP_1, river_model = top_model_metric_history)\n",
    "plot_best_models(\"BP\", Model_1 = y_values_Model_BP_1, river_model = bottom_model_metric_history)\n",
    "plot_best_models(\"Time\", Model_1 = y_values_Model_Time_1, river_model = time_model_metric_history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cnntabular",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
